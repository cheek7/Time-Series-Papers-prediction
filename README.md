# Time-Series-Papers-prediction

# Пояснение к ML-коду: Предсказание публикаций по категориям (LightGBM + CatBoost + TF-IDF)

## Шаг 1. Импорт библиотек
Импортируются необходимые библиотеки:
- `pandas`, `numpy` — работа с таблицами и массивами.
- `lightgbm`, `catboost` — модели градиентного бустинга.
- `TfidfVectorizer` — превращение текстов в числовые признаки.
- `os` — для работы с путями (в коде не используется).

## Шаг 2. Загрузка данных
Загружаются два CSV-файла:
- `train.csv` — данные с датами и количеством публикаций;
- `category_description.csv` — текстовые описания категорий.
Даты преобразуются в формат datetime для дальнейшей работы.

## Шаг 3. TF-IDF признаки из текста
Используется `TfidfVectorizer` для извлечения 50 числовых признаков из текстов описания категории.
Эти признаки добавляются в основной датасет `train` с помощью объединения (merge).

## Шаг 4. Обработка по категориям
Для каждой уникальной категории:
- Фильтруются строки;
- Сортируются по дате;
- Вызывается функция генерации временных признаков.

## Шаг 5. Генерация временных признаков
Для каждой строки создаются:
- Временные признаки: неделя, день недели, месяц, выходной и т.д.;
- Скользящие статистики: среднее, максимум, минимум, стандартное отклонение за 7/28/30/90 дней;
- Лаги: сколько публикаций было 7, 14, 28 дней назад;
- Глобальные средние значения по неделям.

Также добавляется `target` — это количество публикаций на 7 дней вперёд.

## Шаг 6. Объединение всех категорий
Объединяются все подготовленные строки в один общий датасет `dataset`.

## Шаг 7. Деление на train, valid, test
- `labeled_data` — строки с известным target;
- `train_dataset` — строки до определенной даты;
- `valid_dataset` — последние 4 недели;
- `test_dataset` — строки, где целевое значение отсутствует (нужно предсказать).

## Шаг 8. Подготовка признаков
Удаляются неиспользуемые столбцы (дата, категория, целевая переменная).  
Оставшиеся используются как входные признаки для моделей.

## Шаг 9. Обучение LightGBM
- Объявляется кастомная метрика Safe MAPE;
- Настраиваются параметры модели (learning_rate, глубина, регуляризация);
- Модель обучается с использованием валидации и ранней остановки.

## Шаг 10. Обучение CatBoost
- Похожие параметры;
- Используется встроенная метрика MAPE;
- Также применяется ранняя остановка.

## Шаг 11. Предсказания и блендинг
- Получаются предсказания от обеих моделей;
- Объединяются (60% от LightGBM, 40% от CatBoost).

## Шаг 12. Блендинг с baseline
- Считается корреляция между предсказанием и baseline;
- Если < 0.9, делается дополнительное сглаживание (70% текущее + 30% baseline).

## Шаг 13. Формирование submission
- Генерируется таблица предсказаний на 8 недель для каждой категории;
- Результат сохраняется в файл `top1_submission.csv`.

**Готово!**
